= Architectural Design Patterns
Daniel Hinojosa
:source-highlighter: pygments
:pygments-style: friendly
:icons: font
:imagesdir: ./images
:project-name: advanced_java
:star: *
:starline: *_
:starstar: **
:underscore: _
:toc: left
:backend: revealjs
:customcss: custom.css
:topic: state=title
:icons: font
:experimental:


== Demo 1: CQRS (Command Query Responsibility Segregation)

=== Launch Initial Containers

. Open the _cqrs_ module folder
. Right-click on the _docker-compose.yml_ file and select "Compose Up - Select Services", deselect all the checkmarks, and select `connect ksqldb-cli postgres control-center mongo mongo-express`
. Login into `connect` container by using either `Attach Shell` on Gitpod or `docker exec -it connect /bin/bash`

=== Create a JDBC Connector

. Run the following in the container a JDBC Connect that reads from postgres - `confluent-hub install confluentinc/kafka-connect-jdbc:10.7.1`
. Select `2. / (where this tool is installed)`
. Answer `y` to `Do you want to install this into /usr/share/confluent-hub-components?`
. Answer `y` to `I agree to the software license agreement (yN)`
. Answer `y` to `Do you want to continue?`
. Answer `y` to `Do you want to update all detected configs? (yN)`

=== Create a MongoDB Connector

. Run the following in the container `confluent-hub install mongodb/kafka-connect-mongodb:1.11.2`, or whatever the latest version is from https://confluent.io/hub[Confluent Hub]
. Select `2. / (where this tool is installed)`
. Answer `y` to `Do you want to install this into /usr/share/confluent-hub-components?`
. Answer `y` to `I agree to the software license agreement (yN)`
. Answer `y` to `Do you want to continue?`
. Answer `y` to `Do you want to update all detected configs? (yN)`
. Exit the container using `exit`
. Restart the container in GitPod or using `docker restart connect`

=== Run the Data Generator

. Run the `CreateStocks` application by doing the following:
.. Create a new terminal
.. `cd cqrs`
.. Run `mvn clean compile exec:java -Dexec.mainClass=com.evolutionnext.cqrs.CreateStocks` to generate data.

=== View the Postgres Database

. Login into your `postgres` container using `Attach Shell` or `docker exec -it postgres /bin/bash`
. Run the following: `export PGPASSWORD='docker'`
. Run the following: `psql -d docker -U docker`
. In the Postgres shell run  `\dt` which will show all the tables
. In the Postgres shell run `\d stock_trade`, which will show specific table schema
. Run `SELECT * from stock_trade;` and ensure that the data exists
. Exit the `postgres` container by kbd:[CTRL+D] and typing `exit` in the shell

=== Create the Postgres Connector

. Log into the Confluent Control Center
. Select your cluster `controlcenter.cluster`
. Select _Connect_ in the menu
. Select the _connect_default_ cluster
. Select the btn:[Add Connector] button
. Select the btn:[JdbcSourceConnector] button
. Add the following in the respective fields:
.. *Key Converter Class* - `io.confluent.connect.avro.AvroConverter`
.. *Value Converter Class* - `io.confluent.connect.avro.AvroConverter`
.. *JDBC URL* - `jdbc:postgresql://postgres:5432/`
.. *JDBC User* - `docker`
.. *JDBC Password* - `docker`
.. *Database Dialect* `PostgreSqlDatabaseDialect`
.. *Table Loading Mode* `incrementing`
.. *Topic Prefix* - `postgres_`
.. *Additional Properties* -  `key.converter.schema.registry.url` set to  `http://schema-registry:8081`
.. *Additional Properties* - `value.converter.schema.registry.url` set to `http://schema-registry:8081`
. Click btn:[Next]
. Verify the JSON output, then select btn:[Launch]
. Go back to the home page of the Confluent Control Center
. Go to the topics, and select _postgres_stock_trade_
. Select the _Messages_ menu
. View the data coming for data loading
. You can stop the database loading by initiating kbd:[CTRL+C]

=== Enrich the Data using KSQLDB


. Go to KSQL-CLI Container by either attaching to the `ksqldb-cli` shell using `docker exec ksqldb-cli /bin/bash`
. Run a ksql terminal that will attach to the KSQLDB Server using the following command
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ ksql http://ksqldb-server:8088
----
+
. In the KSQLDB CLI, Create a Stream
+
[source,ksql]
----
CREATE STREAM stock_trades WITH (
KAFKA_TOPIC = 'postgres_stock_trade',
VALUE_FORMAT = 'AVRO'
);
----
+
. Enter into the CLI the following:
+
[source,ksql]
----
SET 'auto.offset.reset'='earliest';
----
+
. Show the live data coming from the source
+
[source,ksql]
----
select * from STOCK_TRADES emit changes;
----
+
. Let's try something fancy, let's get a count of all the stocks and their count
+
[source,ksql]
----
select STOCK_SYMBOL, AS_VALUE(STOCK_SYMBOL) as symbol, count(*) as count from STOCK_TRADES group by stock_symbol EMIT CHANGES;
----
+
. Create an aggregate topic from the above statement
+
[source,ksql]
----
create table stock_count with (PARTITIONS = 3, VALUE_FORMAT = 'JSON') as select STOCK_SYMBOL, AS_VALUE(STOCK_SYMBOL) as symbol, count(*) as count from STOCK_TRADES group by stock_symbol EMIT CHANGES;
----
. Go to the topics, and select _STOCK_COUNT_
. Select the _Messages_ menu
. View the data coming for data loading

=== Create a MongoDB Sink

. Go back to the _Confluent Control Center_
. Click on the menu:Connect[] menu
. Select the _connect_default_ cluster
. Click on the btn:[Upload connector config file] button
. Select the file from the _cqrs_ module _src/main./resources/mongosink.json_
. Click btn:[Next]
. Verify the JSON output, then select btn:[Launch]
. Open the browser to the `mongo-express` container, port `10002` using the admin username `admin` and password `pass`
. Locate the database _STOCK_COUNT_
. Locate the collection _stock_counts_
. Click btn:[View]

image::stop.png[width=15%, height=15%, align=center]

== Lab 8: Valet Key

. Open the _value-key_ folder in your Explorer
. Right click on _docker-compose.yml_ and select _Compose Up_
. Click on the Docker menu, and right-click on the vault
container and select "Attach Shell"
. In the shell, enter the following
+
[source, sh, subs="attributes,quotes,verbatim"]
----
export VAULT_ADDR='http://127.0.0.1:8200'
----
+
. Next enter your `root` credential
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ export VAULT_TOKEN="root"
----
+
. Log into vault using `vault login`, when prompted for
the password, enter `root`
. Enable the database engine
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ vault secrets enable database
----
+
. Next, you can configure your database configuration.
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ vault write database/config/my-postgresql-database \
    plugin_name="postgresql-database-plugin" \
    allowed_roles="my-role" \
    connection_url="postgresql://{{username}}:{{password}}@postgres:5432/postgres" \
    username="docker" \
    password="docker" \
    password_authentication="scram-sha-256"
----
+
. Next, let's add a role. The role is how do we provide access to anyone who
requires it.
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ vault write database/roles/my-role \
    db_name="my-postgresql-database" \
    creation_statements="CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}'; \
        GRANT SELECT ON ALL TABLES IN SCHEMA public TO \"{{name}}\";" \
    default_ttl="1h" \
    max_ttl="24h"
----
+
. We can then read a new credential, providing us with a valet-key
used to communicate with the database directly. This also has a TTL. Vault
can be used to implement the pattern, or you can use it to as password
management system and credential rotation.
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ vault read database/creds/my-role
----
+
. Right-click on the postgres container in the docker menu
and select "Attach Shell".
. Once in the shell, log into your postgres:
+
[source, sh, subs="attributes,quotes,verbatim"]
----
$ psql -h localhost -p 5432 -U docker -d postgres
----
+
. Locate the credential that has just been created
+
[source, sh, subs="attributes,quotes,verbatim"]
----
postgres=# SELECT rolname FROM pg_roles;
----
+
. Open port `8200` is your gitpod.io, and ensure
that you can see the same information. This is the web interface.
. Go back to the Explorer in your Visual Studio Code and right-click on the _docker-compose.yml_
in the _valet-key_ folder and select "Docker Compose Down"

image::stop.png[width="15%", height="15%", align="center"]

== Demo 2: Pinot

The following is taken from the https://dev.startree.ai/docs/pinot/getting-started/quick-start [StarTree Quick Start]

. To launch the quickstart, run the command below
+
[source,shell]
----
docker run \
  -p 9000:9000 \
  apachepinot/pinot:1.0.0 QuickStart \
  -type hybrid
----
+
